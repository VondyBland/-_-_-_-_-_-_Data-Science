ДМИТРИЕВ АЛЕКСАНДР РОСТИСЛАВОВИЧ

В следующей работе представлен процесс обработки данных, составления аналитических гипотез и анализ данных. Построение моделей и их оптимизация под имеющиеся ограничения.


# 1.1 "How much are we selling, and who are we selling to?" или обработка аномалий amount


Если присмотреться к этим данным, задаваясь вопросом - ошибка ли отрицательные значения amount? Мы еще и покупаем у посетителей товары или просто случайно приписываем минусы? Или таким образом записывались возвраты, если товары подлежат возврату?

Товары не покупаются у посетителей, ведь согласно имеющимся условиям - данные исключительно по продажам, поэтому будем исходить из этого. У нас нет возможности узнать, являются ли эти данные  но при этом минус может быть приписан случайно.

К тому же, при расмотрении histplot'ов от -1 до 0, 0 до 1, 1 до 2 - можно заметить, что распределение в положительных разделениях - равномерное. Что немного не логично, ведь товары в небольших количествах буду покупать все равно чаще. И если провести модулирование - ситуация изменится примерно в отношении 3 к 1, то есть 3 раза купят по немногу за каждую одну "оптовую" покупку. Такой строгий разрыв в распределении amount между 0.5 и 0.51 указывает на неверность данной интерпретации.

Эти аномалии мы трогать не будем далее, хоть они составляют почти 1/8 всех данных - потеря такого количества данных действительно критична.

При этом, стоит отметить, что ввиду отсутствия условного customer_id - мы не можем заткнуть эти данные средними значениями у покупателя, а использование других столбцов для этой задачи не представляется возможным, ведь по большей части - значения amount уникальны до грамма.



---

# 1.2 "We're not in Kansas anymore." или обработка пропущенного place.
Учитывая, что данные изначально отсортированы по порядку места и продуктов - можно вернуть истинные значения place, обратившись к соседним строкам, ведь при рассмотрении неизвестные place не расположены друг с другом.
Напишем функцию, берущую если не верхнее соседнее значение, то нижнее.

После использовании данной функции, можно заметить, что с 342 (изначально их 433) количество неизвестных снизилось до 33, их уже восстановить не получится, так как они либо окружены некорректными значениями price, либо сами ими являются.
Удаляем эти строки

# 1.3 "Every ~~man~~ product has a price" или обработка аномалий price

Были бы это беспорядочные данные - мы могли бы просто заменить их на случайные значения в заданных интервалах или же на медианные / средние и тд.

Так как все транзакции были записаны вручную и для них не использовалась магическая сила древа Эрд, насколько нам известно - стоит учитывать, что ошибочные данные - действительно просто ошибочные, а не выдуманные и написанные с нуля.

Предварительно еще были изучены гипотезы, что это факторы человеческой ошибки и были попытки найти какой-то паттерн в этих ошибках, чтобы вызвать около-реальные значения - безуспешно.

Однако, у нас есть дата продажи, что позволяет нам на основе ближайшей известной цены (в обе стороны) в данном регионе и по данному продукту заменить некорректные данные в ценах, которые по большей части абсурдны, в своих значениях. По принципу предыдущей функции, однако, как  показала практика - она занимала слишком много ресурсов и при множественных попытках оптимизации снизилась только до 3-х минут. Поэтому пришлось отказаться.

Вот немного записей о логике функции: Разделяем дф по городам и затем по продуктам
Там сортируем данные по дэйтайму

После этого ищем ближайшую строку в дф с отрицательной ценой
Смотри дату сверху и дату снизу, соответственно присваиваем и добавляем, что если они одинаковы - берем цену, которая меньше, если даже и цены равны - берем верхнюю цену.
Сохраняем изменения в дф и цикл начинается с начала


Для этого реплейсим временно продукты и города, чтобы мы при циклах могли создать отдельные датафреймы внутри словаря и по ним могли вести наш отбор и замену в условиях цикла.

Основная причина такого костыля - дотошность и неудобство работы через сортировку.

[Предложения по исправлению - ускорение работы, путем создания дф с фильтром, где только отриц значения - затем взятия индекса и затем по индексу искать в оригинальном дф и заменять] - не сильно помогло:\

Первый напрашивающийся вариант после этого - сгруппировать по продуктам, городам и дате (без времени) и выбрать модальное значения за эти даты для покрытия аномальных отрицательных цен, однако, если рассмотреть это более подробно - видно, что цены меняются не при начале нового дня, а в хаотичное время, что тоже стоило бы исправить в дальнейшем, как новому управляющему.



# 2.1 Анализ weather_df

Первоначально стоит ввести лишнюю фиктивную переменную - нормальную погоду, чтобы понимать - насколько ее много и могут ли они влиять на какие-либо данные.
Распределение показывает, что разницы между локациями в погоде практически нету, они имеют равное количесто нормальных и "ненормальных" погодных условий.

Выведем на график только основные фиктивные переменные по погоде - такие большие значения normal - испортят картину.

# 2.2 Разбор cost_df

Первая же напрашивающаяся мысль была - погода должна влиять на себестоимость, звучит как-то разумно, доп траты на транспоритровку, целебные травы зимой не соберешь и т.д.
Но по итогу оказалось, что эти переменные вообще не значимы.

Посчитал наиболее информативным буудет сразу изучение из чего состоит себестоимость, есть ли в себестоимости постоянные издержки и какие вообще факторы влияют. Здесь не была учтена инфляция, хотя было понятно - что влиять она может первоначально только на себестоимость.

## "Praise the Estus!" или Рассмотрим себестоимость по эстусу
При построении обычной регрессионной модели, для понимания влияния имеющихся факторов - становится предельно ясно, что погода никаким образом не влияет на себестоимость, что достаточно необычно.

Гипотеза отклонена, при этом, мы поняли, что в себестоимость заложены постоянные издержки - свободный коэфф значим.

## Рассмотрим себестоимость по эльфийской пыльце

Опять же, видим, что факторы погодных условий не значимы.
Что интересно, в себестоимость эльфийской пыльцы изначально также вложены постоянные издержки.

## Рассмотрим себестоимость по целебным травам

Погодные условия опять не значимы, однако возникает другая проблема - не значим параметр по Анор-Лондо, при этом, если посмотреть - целебные травы в нем производятся. Корреляция здесь тоже очень маленькая и отрицательная.

Удалить данную фиктивную переменную было бы неверно - так как мы бы не смогли прогнозировать по этому городу. Скорее всего, этот город не вносит значительного вклада потому, что это делают другие фиктивные переменные за него. Так что можно сказать, что скорее Анор Лондо сам по себе не влияет на цену трав, однако сам факт того, что производства не в других городах - влияет.

# 2.3 Разбор competition
Недооцененные моими коллегами данные, благодаря которым изначально планировалось построить модели, исходя из которых строилась бы уже основная модель - спойлер(не получилось).

Эти данные позволяют оценить ценовую политику наших конкурентов.

И сразу можно заметить, что все конкуренты в среднем меняют цену по всем продуктам на одно и то же количество. 

Насколько схожа в этом плане наша компания?

Спустя несколько махинаций с датафреймами и  выводом графиков - видим, насколько не сильно мы различаемся в ценовой политике с конкурентами. В целом разницы практически нету. Поражает, однако, что пока в среднем у конкурентов цена на целебные травы повышается на +-13 серебряных - мы повышаем её на 17.

Возможно при планировании нашей цены, стоит отталкиваться и от ценовой политики наших конкурентов.


# 2.4 Разбор transaction

Чего-то уникального здесь не сказать - только удивляют эти резкие падения спроса и цены во 2, 10, 11, 12 месяцах. Причем они не вызваны удалением большого количества данных - было проверено с модулированием спроса. Видимо сезонный кризис у них там.

Было много раздумий - как отобразить всю информацию при таком большом количестве комбинаций городов, товаров, конкурентов и еще годов и месяцев - вспомнил про тримапы, отличная вещь, хоть и не самая презентабельная.

Также, что удивляет - равномерное распределение спроса на товары везде! Это не логично, не реалистично и скучно.

Мы уже знаем, что у нас есть сезонность спроса - однако, появилась также разумная гипотеза - начти влияние времени суток. К сожалению оно не нашлось.

# 3. Модели

Изначально - план был, построить:
* Прогноз погоды (или замена на основе средних или модальных значений за прошлые месяцы)
* Прогнозирование спроса на основе города, товара, месяцев, погоды и средней цены в месяце.
* Основная модель прогнозирования цены, учитывая все остальные спрогнозированные значения.
* Оптимизация результатов модели под имеющиеся ограничения.

Однако на середине пути, а именно тестирование моделей по конкурентам - я не смог использовать обученную модель на новых данных. Были перепробованы всевозможные известные мне варианты, перелазанный stackoverflow, замучанные AI, но безуспешно. 

Доходило до записей формулы отвалидированного полинома 3 степени вручную - а это сотни переменных (тоже безуспешно). Поэтому до финального задания я так и не смог добраться.

Про модель себстоимости сказать особого нечего, она довольно простая, из смешного - включал в нее обработанные инфляцией значения себестоимости и удивлялся хорошему качеству. Отсутствие сна - зло.

На каком-то этапе осознал, что в идеале иметь отдельную модель для каждой комбинации, но это уже слишком, поэтому остановился на 3 моделях - на каждый товар, ведь зависимости все-таки оказались разные. Сделал исключение для моделей по конкурентам - надеялся увидеть сильное различие между ценовыми политиками каждой компании, хотя их практически не обнаружилось.

При построении полинома - получается очень точная модель, что в итоге бы сильно помогло.

Другие отпланированные модели построить не успелось, очень много времени съели попытки вывести формулы/модель в дф с другой длиной, чем в тренировочном.

# 4. Оптимизация

Касательно оптимизации до последнего момента не было четких идей - дойду, разберусь. По итогу не дошел, поэтому и не разобрался, видимо. А так, разобрал бы поподробнее constrained regressions и динамическое программирование, думаю второе бы и подошло по итогу, когда нужно было бы оптимизировать готовые прогнозные значения.

___
---
# Special: Не включенное

## "Inflation is like a box of chocolates; you never know how much it's gonna eat into your savings." или Строим инфляцию

Расчет инфляции в условиях данного датафрейма ограничивает широкий спектр факторов, влияющих на рост цен - себестоимость в данном случае, как указано, зависит от места и даты производства товара. 

Однако стоит удостовериться, что лишь эти два фактора оказывают влияние.

Из имеющихся в расположении данных только погода может гипотетически влиять на себестоимость и, соответственно, мешать нам в расчете инфляции.

Стоит проверить, есть ли действительно связь между данными параметрами.

Первоначально - зависимости нет, однако стоит проверить более подробно, может быть при включении фиктивных значений, месяца и года появится какая-либо связь.

## difference with prices

Как можно заметить, после объединения сводной таблицы с дф и проверки на корреляцию, значимости и не видно, однако это дает нам возможность более подробно рассмотреть различия в ценообразовании между регионами.

И если обратить внимание на зависимости между ценой и разницами средних цен других регионов - подтверждается закономерность данной связи.



## God help us - планы по оптимизации

Основная идея - собрать несколько моделей для каждой пары продуктов и городов, а также преобразовать политики ценоизменения конкурентов в алгоритм для высчета цены как одни из вариантов.

Затем используем алгоритм для оптимизации.
Смотрим какая из моделей лучше всего подходит для каждой группы товаров.

Последний день из данных и соответственно - наш первый день - 


Построить модели прогнозирования себестоимости, учитывая все определенные ранее факторы. + Возможно средний рост цен в этот период времени.

На основе имеющихся прогнозов рассчитать предпологаемую цену товара? Возможно используя имеющиеся данные до этого - то есть отталкиваться от весов в моделях прогнозирования цены товара на основе факторов + себестоимости!



## God destroys competitors - we take their tactics

Построим модель прогнозирования на основе данных конкурентов. Учтем дату (дни со старта отсчета), продукты, города и самих конкурентов.

Предварительно проверим, влияет ли погода на цену - как видим, значительной корреляции нет.

Введем фиктивные переменные, построим модель и выведем интересующую нас статистику. Сразу видим отличные результаты. Рассмотрим дальнейшие варианты

[ВЫВОДЫ ПО МОДЕЛЯМ]

Использование L1 (Lasso) И L2 (Ridge), их валидация и объединение не показало результатов лучше, поэтому для избежания лишней информации в итоговую работу они выведены не будут, а вот построение полинома и его валидация наилучшей для этих данных степени (3) показало. 0.99 R^2 в моделях всех конкурентов.

У нас теперь есть четыре модели, по которой можно прогнозировать цену, на основе данных конкурентов.


## Доработка модели конкурентов 
Предположим, что себестоимость для всех конкурентов и нас, равна выданным нам данным по себестоимости.

## Данные для модели

Все таки свожусь к мнению, что нужна модель для каждого продукта. То есть 3 датафрейма

Прогноз погоды!
Прогноз инфляции! Тут надо проверить на сезонность! И учесть больше последние тенденции.
Прогноз себестоимости с учетом погоды и себестоимости и инфляции!

Учесть методику формирования цены конкурентов - на эти 90 дней построить модель и тогда присоединить.

Прогноз спроса! Несмотря на то, что он практически постоянен.

___